{
  "comparision": "COMPARISON",
  "guide mode": "Guide Mode",
  "optimal mode": "Optimal Mode",
  "custom mode": "Custom Mode",
  "benchmark mode": "Benchmark Mode",
  "cluster": "Cluster",
  "models": "Models",
  "others": "Others",
  "input": "Input",
  "shouldset": "should be set",
  "autocalc": "Automatic Calculation",
  "next": "NEXT",
  "calculate": "CALCUTATE",
  "nodata": "No Data",
  "step cluster": "Determine the GPU type, GPU numbers, per-host network bandwidth and Network topology.",
  "step models": "Determine the model type and input minibatch size.",
  "step other1": "Determine the optimization strategy.",
  "step other2": "Determine the 3D parallel degree.",
  "step other3": "Determine the batch size and microbatch size.",
  "step other4": "Determine the datatype.",
  "step input": "Input the total number of tokens / data parallel degree / number of epochs.",
  "import": "IMPORT",
  "download tem": "DOWNLOAD TEMPLATE",
  "step1": "Step1.",
  "step2": "Step2.",
  "step3": "Step3.",
  "step4": "Step4.",
  "custom process": "Customize the computation process",
  "custom step1": "Download our excel template.",
  "custom step2": "Fill in necessary input.",
  "custom step3": "Customize intermediate computation formulas.",
  "custom step4": "Upload your template file with required computation results in [Output] Sheet.",
  "wait calc": "Waiting for calculation...",
  "select title": "Select",
  "parameters": "Parameters",
  "benchmark progress": "Benchmark your training with our tracing program",
  "benchmark step1": "Download and run our benchmark program at",
  "benchmark step2": "Collect and upload the tracing file 「benchmark.csv」to the calculator.",
  "benchmark step3": "Check the real timeline of a specific iteration in the benchmark training process.",
  "link": "Link",
  "tensor recommend": "No larger than recommended value ({{value}}) to balance GPU communication/computation time.",
  "pipeline recommend": "No smaller than recommended value ({{value}}) to avoid OOM",
  "microbatch recommend": "No larger than  recommended value ({{value}}) to reduce pipeline bubble time.",
  "pp_dp_tp_recommend": "The number of GPU is {{value}} and the number of TP × PP × DP should be be equal to GPU numbers.",
  "batch_recommend": "The value of batch size should >= DP*microbatch size.",
  "pipeline tips": "Activation out of memory, try to increase tensor parallel degree or decrease minibatch size",
  "pipeline divide tips": "Need to be able to divide number of model layers",
  "microsize tips": "Need to be able to divide minibatch size",
  "export": "EXPORT",
  "select compare": "Select records to compare",
  "cancel": "CANCEL",
  "return": "RETURN",
  "compare": "COMPARE",
  "add item": "Add item",
  "add": "ADD",
  "model": "Model",
  "minibatch": "Minibatch size",
  "model params number": "The number of parameters of models",
  "microbatch": "Microbatch size",
  "batch size": "Batch size",
  "datatype": "Datatype",
  "token number": "Total number of tokens",
  "data parallel": "Data parallel degree",
  "epochs": "Number of epochs",
  "optimization strategy": "Optimization strategy",
  "doc": "Documentation"
}
